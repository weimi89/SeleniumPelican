# æ”¹é€²å»ºè­°

## æ¦‚è¿°

åŸºæ–¼å° SeleniumPelican å°ˆæ¡ˆçš„æ·±å…¥åˆ†æï¼Œæœ¬æ–‡æª”æå‡ºäº†ä¸€ç³»åˆ—æ”¹é€²å»ºè­°ï¼Œæ—¨åœ¨æå‡å°ˆæ¡ˆçš„å¯ç¶­è­·æ€§ã€æ•ˆèƒ½ã€å®‰å…¨æ€§å’Œæ“´å±•æ€§ã€‚é€™äº›å»ºè­°æŒ‰å„ªå…ˆç´šåˆ†é¡ï¼Œä¸¦æä¾›äº†å…·é«”çš„å¯¦ä½œæ–¹å‘ã€‚

## ğŸš€ é«˜å„ªå…ˆç´šæ”¹é€² (3-6å€‹æœˆ)

### 1. è‡ªå‹•åŒ–æ¸¬è©¦æ¡†æ¶å»ºç«‹

**ç¾æ³å•é¡Œ**:
- ç¼ºä¹è‡ªå‹•åŒ–æ¸¬è©¦ï¼Œä¾è³´æ‰‹å‹•æ¸¬è©¦
- é‡æ§‹é¢¨éšªé«˜ï¼Œå®¹æ˜“å¼•å…¥è¿´æ­¸å•é¡Œ
- ç¨‹å¼ç¢¼å“è³ªé›£ä»¥ä¿è­‰

**å»ºè­°æ–¹æ¡ˆ**:
```python
# å»ºç«‹æ¸¬è©¦æ¡†æ¶çµæ§‹
tests/
â”œâ”€â”€ unit/                    # å–®å…ƒæ¸¬è©¦
â”‚   â”œâ”€â”€ test_base_scraper.py
â”‚   â”œâ”€â”€ test_multi_account_manager.py
â”‚   â””â”€â”€ test_utils.py
â”œâ”€â”€ integration/             # æ•´åˆæ¸¬è©¦
â”‚   â”œâ”€â”€ test_login_flow.py
â”‚   â”œâ”€â”€ test_payment_scraper.py
â”‚   â””â”€â”€ test_data_extraction.py
â”œâ”€â”€ e2e/                     # ç«¯åˆ°ç«¯æ¸¬è©¦
â”‚   â””â”€â”€ test_complete_workflow.py
â””â”€â”€ fixtures/                # æ¸¬è©¦è³‡æ–™
    â”œâ”€â”€ mock_accounts.json
    â””â”€â”€ sample_html/
```

**å¯¦ä½œè¨ˆåŠƒ**:
1. æ•´åˆ pytest æ¸¬è©¦æ¡†æ¶
2. å»ºç«‹ Mock WebDriver ç”¨æ–¼å–®å…ƒæ¸¬è©¦
3. å¯¦ä½œæ¸¬è©¦è³‡æ–™å·¥å» 
4. è¨­å®š CI/CD è‡ªå‹•æ¸¬è©¦

**é æœŸæ•ˆç›Š**:
- æ¸¬è©¦è¦†è“‹ç‡é”åˆ° 80%+
- é‡æ§‹ä¿¡å¿ƒæå‡
- å›æ­¸å•é¡Œæ¸›å°‘ 90%

---

### 2. é…ç½®é©—è­‰å’Œç®¡ç†å¢å¼·

**ç¾æ³å•é¡Œ**:
```python
# ç›®å‰çš„é…ç½®è¼‰å…¥ç¼ºä¹é©—è­‰
with open('accounts.json', 'r') as f:
    config = json.load(f)  # æ²’æœ‰é©—è­‰é…ç½®æ ¼å¼
```

**å»ºè­°æ–¹æ¡ˆ**:
```python
from pydantic import BaseModel, validator
from typing import List, Optional

class AccountConfig(BaseModel):
    username: str
    password: str
    enabled: bool = True
    display_name: Optional[str] = None

    @validator('username', 'password')
    def validate_not_empty(cls, v):
        if not v.strip():
            raise ValueError('ä½¿ç”¨è€…åç¨±å’Œå¯†ç¢¼ä¸èƒ½ç‚ºç©º')
        return v

class SettingsConfig(BaseModel):
    headless: bool = False
    download_base_dir: str = './downloads'
    timeout: int = 30
    retry_count: int = 3

    @validator('timeout', 'retry_count')
    def validate_positive(cls, v):
        if v <= 0:
            raise ValueError('è¶…æ™‚æ™‚é–“å’Œé‡è©¦æ¬¡æ•¸å¿…é ˆå¤§æ–¼ 0')
        return v

class ApplicationConfig(BaseModel):
    accounts: List[AccountConfig]
    settings: SettingsConfig

# ä½¿ç”¨é©—è­‰çš„é…ç½®è¼‰å…¥
def load_validated_config(config_path: str) -> ApplicationConfig:
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        return ApplicationConfig(**data)
    except ValidationError as e:
        raise ConfigurationError(f"é…ç½®æª”æ¡ˆæ ¼å¼éŒ¯èª¤: {e}")
```

**å¯¦ä½œæ­¥é©Ÿ**:
1. å¼•å…¥ pydantic é€²è¡Œé…ç½®é©—è­‰
2. å»ºç«‹é…ç½® schema å®šç¾©
3. å¯¦ä½œé…ç½®æª”æ¡ˆè‡ªå‹•ç”Ÿæˆå·¥å…·
4. æ–°å¢é…ç½®æ›´æ–°å’Œé·ç§»æ©Ÿåˆ¶

---

### 3. æ—¥èªŒå’Œç›£æ§ç³»çµ±å®Œå–„

**å»ºè­°å¯¦ä½œ**:
```python
import structlog
from pathlib import Path

# çµæ§‹åŒ–æ—¥èªŒé…ç½®
def setup_logging():
    log_dir = Path('logs')
    log_dir.mkdir(exist_ok=True)

    structlog.configure(
        processors=[
            structlog.stdlib.filter_by_level,
            structlog.stdlib.add_log_level,
            structlog.stdlib.PositionalArgumentsFormatter(),
            structlog.processors.TimeStamper(fmt="iso"),
            structlog.processors.StackInfoRenderer(),
            structlog.dev.ConsoleRenderer()
        ],
        context_class=dict,
        logger_factory=structlog.stdlib.LoggerFactory(),
        cache_logger_on_first_use=True,
    )

# å¢å¼·çš„æ—¥èªŒè¨˜éŒ„
class BaseScraper:
    def __init__(self):
        self.logger = structlog.get_logger(
            scraper_type=self.__class__.__name__
        )

    def login(self, username, password):
        with self.logger.bind(username=username):
            self.logger.info("é–‹å§‹ç™»å…¥æµç¨‹")
            try:
                result = self._perform_login(username, password)
                self.logger.info("ç™»å…¥æˆåŠŸ", duration=self._get_duration())
                return result
            except Exception as e:
                self.logger.error("ç™»å…¥å¤±æ•—", error=str(e), exc_info=True)
                raise
```

**ç›£æ§æŒ‡æ¨™**:
- åŸ·è¡Œæ™‚é–“ç›£æ§
- æˆåŠŸç‡çµ±è¨ˆ
- éŒ¯èª¤é¡å‹åˆ†æ
- è³‡æºä½¿ç”¨æƒ…æ³

---

## ğŸ”§ ä¸­å„ªå…ˆç´šæ”¹é€² (6-12å€‹æœˆ)

### 4. éåŒæ­¥è™•ç†æ”¯æ´

**ç›®æ¨™**: æå‡å¤šå¸³è™Ÿè™•ç†æ•ˆèƒ½

**æŠ€è¡“æ–¹æ¡ˆ**:
```python
import asyncio
from selenium import webdriver
from selenium.webdriver.chrome.service import Service

class AsyncMultiAccountManager:
    def __init__(self, scraper_class, max_concurrent=3):
        self.scraper_class = scraper_class
        self.semaphore = asyncio.Semaphore(max_concurrent)

    async def process_account_async(self, account):
        async with self.semaphore:
            # åœ¨åŸ·è¡Œç·’æ± ä¸­åŸ·è¡Œ Selenium æ“ä½œ
            loop = asyncio.get_event_loop()
            return await loop.run_in_executor(
                None,
                self._sync_process_account,
                account
            )

    async def execute_all_async(self):
        accounts = self.load_accounts()
        tasks = [
            self.process_account_async(account)
            for account in accounts
            if account['enabled']
        ]
        return await asyncio.gather(*tasks, return_exceptions=True)

# ä½¿ç”¨ç¯„ä¾‹
async def main():
    manager = AsyncMultiAccountManager(PaymentScraper, max_concurrent=3)
    results = await manager.execute_all_async()
    print(f"ä¸¦è¡Œè™•ç†å®Œæˆï¼Œçµæœæ•¸é‡: {len(results)}")
```

**é æœŸæ•ˆç›Š**:
- å¤šå¸³è™Ÿè™•ç†æ™‚é–“ç¸®çŸ­ 60%
- è³‡æºåˆ©ç”¨ç‡æå‡
- æ›´å¥½çš„ä½¿ç”¨è€…é«”é©—

---

### 5. è³‡æ–™è™•ç†å’Œè¼¸å‡ºå¢å¼·

**ç¾æ³å•é¡Œ**:
- åªæ”¯æ´ Excel è¼¸å‡ºæ ¼å¼
- ç¼ºä¹è³‡æ–™æ¸…ç†å’Œé©—è­‰
- ç„¡æ³•è‡ªå®šç¾©è¼¸å‡ºçµæ§‹

**å»ºè­°æ”¹é€²**:
```python
from abc import ABC, abstractmethod
from typing import List, Dict, Any
import pandas as pd

class DataProcessor(ABC):
    @abstractmethod
    def process(self, raw_data: List[Dict]) -> List[Dict]:
        pass

class DataExporter(ABC):
    @abstractmethod
    def export(self, data: List[Dict], filename: str) -> str:
        pass

class PaymentDataProcessor(DataProcessor):
    def process(self, raw_data: List[Dict]) -> List[Dict]:
        # è³‡æ–™æ¸…ç†å’Œé©—è­‰
        processed = []
        for record in raw_data:
            # æ¸…ç†ç©ºç™½å­—ç¬¦
            cleaned = {k: str(v).strip() for k, v in record.items()}
            # è³‡æ–™é©—è­‰
            if self.validate_record(cleaned):
                processed.append(cleaned)
        return processed

    def validate_record(self, record: Dict) -> bool:
        required_fields = ['payment_id', 'amount', 'date']
        return all(field in record and record[field] for field in required_fields)

class ExcelExporter(DataExporter):
    def export(self, data: List[Dict], filename: str) -> str:
        df = pd.DataFrame(data)
        # æ ¼å¼åŒ–æ—¥æœŸ
        if 'date' in df.columns:
            df['date'] = pd.to_datetime(df['date']).dt.strftime('%Y-%m-%d')

        excel_path = f"{filename}.xlsx"
        with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:
            df.to_excel(writer, sheet_name='è³‡æ–™', index=False)
            # æ–°å¢æ ¼å¼åŒ–
            worksheet = writer.sheets['è³‡æ–™']
            for column in worksheet.columns:
                max_length = max(len(str(cell.value or '')) for cell in column)
                worksheet.column_dimensions[column[0].column_letter].width = min(max_length + 2, 50)

        return excel_path

class CSVExporter(DataExporter):
    def export(self, data: List[Dict], filename: str) -> str:
        df = pd.DataFrame(data)
        csv_path = f"{filename}.csv"
        df.to_csv(csv_path, index=False, encoding='utf-8-sig')
        return csv_path

# æ•´åˆåˆ°çˆ¬èŸ²ä¸­
class EnhancedBaseScraper(BaseScraper):
    def __init__(self, data_processor=None, data_exporter=None):
        super().__init__()
        self.data_processor = data_processor or PaymentDataProcessor()
        self.data_exporter = data_exporter or ExcelExporter()

    def export_results(self, raw_data: List[Dict], filename: str):
        processed_data = self.data_processor.process(raw_data)
        return self.data_exporter.export(processed_data, filename)
```

---

### 6. Web API ä»‹é¢é–‹ç™¼

**ç›®æ¨™**: æä¾› REST API ä¾›å…¶ä»–ç³»çµ±æ•´åˆ

**æŠ€è¡“æ¶æ§‹**:
```python
from fastapi import FastAPI, BackgroundTasks, HTTPException
from pydantic import BaseModel
from typing import List, Optional
import uuid

app = FastAPI(title="SeleniumPelican API", version="2.0.0")

class ScrapingRequest(BaseModel):
    scraper_type: str  # 'payment', 'freight', 'unpaid'
    accounts: List[str]  # å¸³è™Ÿåç¨±åˆ—è¡¨
    parameters: Optional[Dict] = {}

class ScrapingJob(BaseModel):
    job_id: str
    status: str  # 'pending', 'running', 'completed', 'failed'
    results: Optional[List[Dict]] = None
    error_message: Optional[str] = None

# ä»»å‹™ç®¡ç†
job_store = {}

@app.post("/api/v1/scrape", response_model=Dict)
async def create_scraping_job(request: ScrapingRequest, background_tasks: BackgroundTasks):
    job_id = str(uuid.uuid4())
    job = ScrapingJob(job_id=job_id, status="pending")
    job_store[job_id] = job

    background_tasks.add_task(execute_scraping_job, job_id, request)

    return {"job_id": job_id, "message": "çˆ¬å–ä»»å‹™å·²å»ºç«‹"}

@app.get("/api/v1/jobs/{job_id}", response_model=ScrapingJob)
async def get_job_status(job_id: str):
    if job_id not in job_store:
        raise HTTPException(status_code=404, detail="ä»»å‹™ä¸å­˜åœ¨")
    return job_store[job_id]

async def execute_scraping_job(job_id: str, request: ScrapingRequest):
    job = job_store[job_id]
    job.status = "running"

    try:
        # åŸ·è¡Œçˆ¬å–ä»»å‹™
        scraper_class = get_scraper_class(request.scraper_type)
        manager = MultiAccountManager(scraper_class)
        results = manager.execute_for_accounts(request.accounts)

        job.status = "completed"
        job.results = results
    except Exception as e:
        job.status = "failed"
        job.error_message = str(e)
```

---

## ğŸŒŸ ä½å„ªå…ˆç´šæ”¹é€² (1-2å¹´)

### 7. æ™ºæ…§é©—è­‰ç¢¼è™•ç†

**æŠ€è¡“æ¢ç´¢**:
```python
import cv2
import pytesseract
from PIL import Image

class IntelligentCaptchaHandler:
    def __init__(self):
        self.ocr_engine = pytesseract
        self.image_processors = [
            self._denoise_image,
            self._adjust_contrast,
            self._threshold_image
        ]

    def recognize_captcha(self, captcha_element) -> Optional[str]:
        # æˆªå–é©—è­‰ç¢¼åœ–ç‰‡
        screenshot = captcha_element.screenshot_as_png
        image = Image.open(io.BytesIO(screenshot))

        # å˜—è©¦ä¸åŒçš„åœ–åƒè™•ç†æ–¹æ³•
        for processor in self.image_processors:
            processed_image = processor(image)
            text = self._extract_text(processed_image)
            if self._validate_captcha_format(text):
                return text

        return None

    def _extract_text(self, image) -> str:
        # ä½¿ç”¨å¤šç¨® OCR ç­–ç•¥
        configs = [
            '--psm 8 -c tessedit_char_whitelist=0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ',
            '--psm 7 -c tessedit_char_whitelist=0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ',
            '--psm 13 -c tessedit_char_whitelist=0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ'
        ]

        for config in configs:
            try:
                text = pytesseract.image_to_string(image, config=config).strip()
                if len(text) == 4 and text.isalnum():
                    return text.upper()
            except Exception:
                continue

        return ""
```

### 8. å®¹å™¨åŒ–éƒ¨ç½²

**Docker é…ç½®**:
```dockerfile
FROM python:3.11-slim

# å®‰è£ç³»çµ±ä¾è³´
RUN apt-get update && apt-get install -y \
    wget \
    unzip \
    curl \
    xvfb \
    && rm -rf /var/lib/apt/lists/*

# å®‰è£ Chrome
RUN wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | apt-key add - \
    && echo "deb http://dl.google.com/linux/chrome/deb/ stable main" >> /etc/apt/sources.list.d/google.list \
    && apt-get update \
    && apt-get install -y google-chrome-stable \
    && rm -rf /var/lib/apt/lists/*

# å®‰è£ UV
RUN pip install uv

WORKDIR /app
COPY pyproject.toml uv.lock ./
RUN uv sync --frozen

COPY . .

# è¨­å®šç’°å¢ƒè®Šæ•¸
ENV PYTHONPATH=/app
ENV DISPLAY=:99

EXPOSE 8000

CMD ["uv", "run", "uvicorn", "api.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### 9. å¾®æœå‹™æ¶æ§‹æ¢ç´¢

**æ¶æ§‹è¨­è¨ˆ**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   API Gateway   â”‚    â”‚  Config Service â”‚    â”‚  Auth Service   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         v                       v                       v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Scraping Serviceâ”‚    â”‚  Queue Service  â”‚    â”‚ Storage Service â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         v                       v                       v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Scheduler Serviceâ”‚   â”‚Monitoring Serviceâ”‚   â”‚ Notification   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š å¯¦ä½œè·¯ç·šåœ–

### ç¬¬ä¸€å­£åº¦ (Q1)
- [x] æ¶æ§‹æ–‡æª”å®Œæˆ
- [ ] è‡ªå‹•åŒ–æ¸¬è©¦æ¡†æ¶ (80%)
- [ ] é…ç½®é©—è­‰ç³»çµ± (60%)
- [ ] åŸºç¤ç›£æ§æ—¥èªŒ (40%)

### ç¬¬äºŒå­£åº¦ (Q2)
- [ ] æ¸¬è©¦è¦†è“‹ç‡é”åˆ° 80%
- [ ] å®Œæ•´é…ç½®ç®¡ç†ç³»çµ±
- [ ] çµæ§‹åŒ–æ—¥èªŒç³»çµ±
- [ ] åŸºç¤æ•ˆèƒ½ç›£æ§

### ç¬¬ä¸‰å­£åº¦ (Q3)
- [ ] éåŒæ­¥è™•ç†æ”¯æ´
- [ ] å¢å¼·è³‡æ–™è™•ç†
- [ ] Web API åŸå‹
- [ ] æ™ºæ…§é©—è­‰ç¢¼è™•ç†ç ”ç©¶

### ç¬¬å››å­£åº¦ (Q4)
- [ ] å®Œæ•´ Web API
- [ ] å®¹å™¨åŒ–éƒ¨ç½²
- [ ] ç”Ÿç”¢ç’°å¢ƒå„ªåŒ–
- [ ] æ•ˆèƒ½èª¿å„ª

---

## ğŸ’¡ å‰µæ–°æƒ³æ³•æ¢ç´¢

### AI è¼”åŠ©ç•°å¸¸è™•ç†
åˆ©ç”¨æ©Ÿå™¨å­¸ç¿’è­˜åˆ¥å’Œè™•ç†ç•°å¸¸æƒ…æ³ï¼š
- ç•°å¸¸æ¨¡å¼è­˜åˆ¥
- è‡ªå‹•æ¢å¾©ç­–ç•¥
- æ™ºæ…§é‡è©¦æ©Ÿåˆ¶

### åˆ†æ•£å¼çˆ¬å–
æ”¯æ´å¤šæ©Ÿå™¨å”åŒçˆ¬å–ï¼š
- ä»»å‹™åˆ†æ•£æ’ç¨‹
- è² è¼‰å‡è¡¡
- æ•…éšœè½‰ç§»

### å³æ™‚è³‡æ–™æµ
æä¾›å³æ™‚è³‡æ–™æ›´æ–°ï¼š
- WebSocket æ¨é€
- è³‡æ–™è®Šæ›´é€šçŸ¥
- å³æ™‚ç›£æ§é¢æ¿

---

## ğŸ¯ æˆåŠŸæŒ‡æ¨™

### æŠ€è¡“æŒ‡æ¨™
- **æ¸¬è©¦è¦†è“‹ç‡**: >80%
- **ç¨‹å¼ç¢¼å“è³ª**: Maintainability Index >70
- **æ•ˆèƒ½**: å¤šå¸³è™Ÿè™•ç†æ™‚é–“ç¸®çŸ­ 50%
- **ç©©å®šæ€§**: éŒ¯èª¤ç‡ <5%

### æ¥­å‹™æŒ‡æ¨™
- **é–‹ç™¼æ•ˆç‡**: æ–°åŠŸèƒ½é–‹ç™¼æ™‚é–“ç¸®çŸ­ 40%
- **ç¶­è­·æˆæœ¬**: æœˆç¶­è­·æ™‚é–“ <8 å°æ™‚
- **ä½¿ç”¨è€…æ»¿æ„åº¦**: >90%
- **ç³»çµ±å¯ç”¨æ€§**: >99.5%

### å“è³ªæŒ‡æ¨™
- **Bug æ•¸é‡**: æ¯æœˆæ–°å¢ <3 å€‹
- **å›æ­¸å•é¡Œ**: <1%
- **æ–‡æª”å®Œæ•´æ€§**: 100%
- **ç¨‹å¼ç¢¼å¯©æŸ¥é€šéç‡**: >95%

é€™äº›æ”¹é€²å»ºè­°å°‡å”åŠ© SeleniumPelican evolve æˆç‚ºæ›´åŠ ç©©å¥ã€é«˜æ•ˆä¸”æ˜“ç¶­è­·çš„ä¼æ¥­ç´šè‡ªå‹•åŒ–è§£æ±ºæ–¹æ¡ˆã€‚
