# API åƒè€ƒæ–‡æª”

## æ¦‚è¿°

SeleniumPelican æä¾›äº†æ¸…æ™°çš„ API ä»‹é¢ï¼Œè®“é–‹ç™¼è€…èƒ½å¤ è¼•é¬†æ“´å±•åŠŸèƒ½æˆ–æ•´åˆåˆ°å…¶ä»–ç³»çµ±ä¸­ã€‚æœ¬æ–‡æª”è©³ç´°æè¿°äº†æ‰€æœ‰å…¬é–‹çš„é¡åˆ¥ã€æ–¹æ³•å’Œä»‹é¢ã€‚

## ğŸ›ï¸ æ ¸å¿ƒ API

### BaseScraper

**è·¯å¾‘**: `src.core.base_scraper.BaseScraper`

æ‰€æœ‰çˆ¬èŸ²çš„æŠ½è±¡åŸºç¤é¡åˆ¥ï¼Œå®šç¾©äº†æ¨™æº–çš„çˆ¬å–æµç¨‹å’Œé€šç”¨æ–¹æ³•ã€‚

#### é¡åˆ¥å®šç¾©

```python
class BaseScraper(ABC):
    """ç¶²é çˆ¬èŸ²æŠ½è±¡åŸºç¤é¡åˆ¥

    æä¾›æ¨™æº–çš„çˆ¬å–æµç¨‹å’Œé€šç”¨æ–¹æ³•ï¼Œå­é¡åˆ¥éœ€è¦å¯¦ä½œç‰¹å®šçš„æ¥­å‹™é‚è¼¯ã€‚
    """
```

#### ä¸»è¦æ–¹æ³•

##### `__init__(self, config=None)`

å»ºæ§‹å‡½å¼ï¼Œåˆå§‹åŒ–çˆ¬èŸ²å¯¦ä¾‹ã€‚

**åƒæ•¸**:
- `config` (dict, optional): é…ç½®å­—å…¸

**ç¯„ä¾‹**:
```python
scraper = PaymentScraper({
    'timeout': 30,
    'headless': False
})
```

##### `execute(self, account_info)`

ä¸»è¦åŸ·è¡Œæ–¹æ³•ï¼Œå¯¦ä½œ Template Method æ¨¡å¼ã€‚

**åƒæ•¸**:
- `account_info` (dict): å¸³è™Ÿè³‡è¨Šå­—å…¸

**è¿”å›å€¼**:
- `list`: çˆ¬å–çµæœåˆ—è¡¨

**æ‹‹å‡ºç•°å¸¸**:
- `WebDriverException`: ç€è¦½å™¨æ“ä½œå¤±æ•—
- `LoginError`: ç™»å…¥å¤±æ•—
- `DataExtractionError`: è³‡æ–™æå–å¤±æ•—

**ç¯„ä¾‹**:
```python
account = {
    'username': 'test_user',
    'password': 'test_password'
}
results = scraper.execute(account)
```

##### `setup_browser(self, headless=None, download_dir=None)`

è¨­ç½®ç€è¦½å™¨ç’°å¢ƒã€‚

**åƒæ•¸**:
- `headless` (bool, optional): æ˜¯å¦ä½¿ç”¨ç„¡é ­æ¨¡å¼
- `download_dir` (str, optional): ä¸‹è¼‰ç›®éŒ„è·¯å¾‘

**ç¯„ä¾‹**:
```python
scraper.setup_browser(headless=True, download_dir='./downloads')
```

##### `login(self, username, password)`

åŸ·è¡Œç™»å…¥æ“ä½œï¼ŒåŒ…å«é©—è­‰ç¢¼è™•ç†ã€‚

**åƒæ•¸**:
- `username` (str): ä½¿ç”¨è€…åç¨±
- `password` (str): å¯†ç¢¼

**è¿”å›å€¼**:
- `bool`: ç™»å…¥æ˜¯å¦æˆåŠŸ

**ç¯„ä¾‹**:
```python
success = scraper.login('username', 'password')
if success:
    print("ç™»å…¥æˆåŠŸ")
```

##### `navigate_to_query(self)`

å°èˆªåˆ°æŸ¥è©¢é é¢ã€‚

**è¿”å›å€¼**:
- `bool`: å°èˆªæ˜¯å¦æˆåŠŸ

##### `cleanup(self)`

æ¸…ç†è³‡æºï¼Œé—œé–‰ç€è¦½å™¨ã€‚

**ç¯„ä¾‹**:
```python
try:
    results = scraper.execute(account)
finally:
    scraper.cleanup()  # ç¢ºä¿è³‡æºæ¸…ç†
```

#### æŠ½è±¡æ–¹æ³• (å­é¡åˆ¥å¿…é ˆå¯¦ä½œ)

##### `get_query_params(self)`

å–å¾—æŸ¥è©¢åƒæ•¸ã€‚

**è¿”å›å€¼**:
- `dict`: æŸ¥è©¢åƒæ•¸å­—å…¸

##### `process_results(self)`

è™•ç†æŸ¥è©¢çµæœã€‚

**è¿”å›å€¼**:
- `list`: è™•ç†å¾Œçš„çµæœåˆ—è¡¨

#### å·¥å…·æ–¹æ³•

##### `safe_click(self, element, retries=3)`

å®‰å…¨é»æ“Šå…ƒç´ ï¼ŒåŒ…å«é‡è©¦æ©Ÿåˆ¶ã€‚

**åƒæ•¸**:
- `element` (WebElement): Selenium å…ƒç´ 
- `retries` (int): é‡è©¦æ¬¡æ•¸ï¼Œé è¨­ 3

**è¿”å›å€¼**:
- `bool`: é»æ“Šæ˜¯å¦æˆåŠŸ

##### `wait_for_element(self, by, value, timeout=30)`

ç­‰å¾…å…ƒç´ å‡ºç¾ã€‚

**åƒæ•¸**:
- `by` (By): å®šä½æ–¹æ³•
- `value` (str): å®šä½å€¼
- `timeout` (int): è¶…æ™‚æ™‚é–“ï¼ˆç§’ï¼‰

**è¿”å›å€¼**:
- `WebElement`: æ‰¾åˆ°çš„å…ƒç´ 

**æ‹‹å‡ºç•°å¸¸**:
- `TimeoutException`: ç­‰å¾…è¶…æ™‚

---

### MultiAccountManager

**è·¯å¾‘**: `src.core.multi_account_manager.MultiAccountManager`

å¤šå¸³è™Ÿç®¡ç†å™¨ï¼Œè² è²¬æ‰¹æ¬¡è™•ç†å¤šå€‹å¸³è™Ÿã€‚

#### é¡åˆ¥å®šç¾©

```python
class MultiAccountManager:
    """å¤šå¸³è™Ÿæ‰¹æ¬¡è™•ç†ç®¡ç†å™¨"""
```

#### ä¸»è¦æ–¹æ³•

##### `__init__(self, scraper_class)`

å»ºæ§‹å‡½å¼ã€‚

**åƒæ•¸**:
- `scraper_class` (class): çˆ¬èŸ²é¡åˆ¥

**ç¯„ä¾‹**:
```python
manager = MultiAccountManager(PaymentScraper)
```

##### `load_accounts(self, config_path='accounts.json')`

è¼‰å…¥å¸³è™Ÿé…ç½®ã€‚

**åƒæ•¸**:
- `config_path` (str): é…ç½®æª”æ¡ˆè·¯å¾‘

**è¿”å›å€¼**:
- `list`: å¸³è™Ÿåˆ—è¡¨

**æ‹‹å‡ºç•°å¸¸**:
- `FileNotFoundError`: é…ç½®æª”æ¡ˆä¸å­˜åœ¨
- `json.JSONDecodeError`: é…ç½®æ ¼å¼éŒ¯èª¤

##### `execute_all(self)`

æ‰¹æ¬¡åŸ·è¡Œæ‰€æœ‰å•Ÿç”¨çš„å¸³è™Ÿã€‚

**è¿”å›å€¼**:
- `dict`: åŸ·è¡Œçµæœæ‘˜è¦

**ç¯„ä¾‹**:
```python
manager = MultiAccountManager(PaymentScraper)
results = manager.execute_all()
print(f"æˆåŠŸè™•ç† {results['success_count']} å€‹å¸³è™Ÿ")
```

##### `process_account(self, account_config)`

è™•ç†å–®å€‹å¸³è™Ÿã€‚

**åƒæ•¸**:
- `account_config` (dict): å¸³è™Ÿé…ç½®

**è¿”å›å€¼**:
- `dict`: è™•ç†çµæœ

##### `generate_summary(self, results)`

ç”ŸæˆåŸ·è¡Œæ‘˜è¦å ±å‘Šã€‚

**åƒæ•¸**:
- `results` (list): åŸ·è¡Œçµæœåˆ—è¡¨

**è¿”å›å€¼**:
- `dict`: æ‘˜è¦å ±å‘Š

---

## ğŸ”§ å¯¦ä½œé¡åˆ¥ API

### PaymentScraper

**è·¯å¾‘**: `src.scrapers.payment_scraper.PaymentScraper`

ä»£æ”¶è²¨æ¬¾æŸ¥è©¢çˆ¬èŸ²ã€‚

#### ç‰¹æœ‰æ–¹æ³•

##### `set_date_range(self, start_date, end_date)`

è¨­å®šæŸ¥è©¢æ—¥æœŸç¯„åœã€‚

**åƒæ•¸**:
- `start_date` (str): é–‹å§‹æ—¥æœŸ (YYYYMMDD)
- `end_date` (str): çµæŸæ—¥æœŸ (YYYYMMDD)

**ç¯„ä¾‹**:
```python
scraper = PaymentScraper()
scraper.set_date_range('20241201', '20241208')
```

##### `filter_payment_records(self, records)`

éæ¿¾ä»£æ”¶è²¨æ¬¾è¨˜éŒ„ã€‚

**åƒæ•¸**:
- `records` (list): åŸå§‹è¨˜éŒ„åˆ—è¡¨

**è¿”å›å€¼**:
- `list`: éæ¿¾å¾Œçš„è¨˜éŒ„

**éæ¿¾æ¢ä»¶**:
- åŒ…å«ã€Œä»£æ”¶è²¨æ¬¾ã€é—œéµå­—
- åŒ…å«ã€ŒåŒ¯æ¬¾æ˜ç´°ã€é—œéµå­—
- ä¸åŒ…å«ã€Œå·²æ”¶æœªçµå¸³ã€é—œéµå­—

##### `download_excel_file(self, record_link)`

ä¸‹è¼‰ Excel æª”æ¡ˆã€‚

**åƒæ•¸**:
- `record_link` (WebElement): ä¸‹è¼‰é€£çµå…ƒç´ 

**è¿”å›å€¼**:
- `str`: ä¸‹è¼‰æª”æ¡ˆè·¯å¾‘

---

### FreightScraper

**è·¯å¾‘**: `src.scrapers.freight_scraper.FreightScraper`

é‹è²»æŸ¥è©¢çˆ¬èŸ²ã€‚

#### ç‰¹æœ‰æ–¹æ³•

##### `set_month_range(self, start_month, end_month)`

è¨­å®šæŸ¥è©¢æœˆä»½ç¯„åœã€‚

**åƒæ•¸**:
- `start_month` (str): é–‹å§‹æœˆä»½ (YYYYMM)
- `end_month` (str): çµæŸæœˆä»½ (YYYYMM)

##### `extract_freight_data(self, data_element)`

æå–é‹è²»æ•¸æ“šã€‚

**åƒæ•¸**:
- `data_element` (WebElement): åŒ…å«æ•¸æ“šçš„å…ƒç´ 

**è¿”å›å€¼**:
- `dict`: é‹è²»æ•¸æ“šå­—å…¸

---

### UnpaidScraper

**è·¯å¾‘**: `src.scrapers.unpaid_scraper.UnpaidScraper`

é‹è²»æœªè«‹æ¬¾æ˜ç´°çˆ¬èŸ²ã€‚

#### ç‰¹æœ‰æ–¹æ³•

##### `parse_html_table(self, table_html)`

è§£æ HTML è¡¨æ ¼ã€‚

**åƒæ•¸**:
- `table_html` (str): HTML è¡¨æ ¼å­—ç¬¦ä¸²

**è¿”å›å€¼**:
- `list`: è§£æå¾Œçš„æ•¸æ“šåˆ—è¡¨

##### `convert_to_excel(self, data, filename)`

å°‡æ•¸æ“šè½‰æ›ç‚º Excel æª”æ¡ˆã€‚

**åƒæ•¸**:
- `data` (list): æ•¸æ“šåˆ—è¡¨
- `filename` (str): è¼¸å‡ºæª”æ¡ˆå

**è¿”å›å€¼**:
- `str`: Excel æª”æ¡ˆè·¯å¾‘

---

## ğŸ› ï¸ å·¥å…·é¡åˆ¥ API

### browser_utils

**è·¯å¾‘**: `src.core.browser_utils`

ç€è¦½å™¨å·¥å…·æ¨¡çµ„ã€‚

#### å‡½æ•¸

##### `setup_chrome_driver(headless=False, download_dir=None)`

å»ºç«‹ Chrome WebDriver å¯¦ä¾‹ã€‚

**åƒæ•¸**:
- `headless` (bool): æ˜¯å¦ç„¡é ­æ¨¡å¼
- `download_dir` (str): ä¸‹è¼‰ç›®éŒ„

**è¿”å›å€¼**:
- `webdriver.Chrome`: Chrome WebDriver å¯¦ä¾‹

**ç¯„ä¾‹**:
```python
from src.core.browser_utils import setup_chrome_driver

driver = setup_chrome_driver(
    headless=True,
    download_dir='./downloads'
)
```

##### `get_chrome_binary_path()`

å–å¾— Chrome åŸ·è¡Œæª”è·¯å¾‘ã€‚

**è¿”å›å€¼**:
- `str`: Chrome åŸ·è¡Œæª”è·¯å¾‘

**å¹³å°æ”¯æ´**:
- macOS: `/Applications/Google Chrome.app/Contents/MacOS/Google Chrome`
- Windows: `C:\\Program Files\\Google\\Chrome\\Application\\chrome.exe`
- Linux: `/usr/bin/google-chrome`

---

### windows_encoding_utils

**è·¯å¾‘**: `src.utils.windows_encoding_utils`

Windows ç·¨ç¢¼ç›¸å®¹å·¥å…·ã€‚

#### å‡½æ•¸

##### `safe_print(text)`

å®‰å…¨è¼¸å‡ºæ–‡å­—ï¼Œè‡ªå‹•è™•ç†è·¨å¹³å°ç·¨ç¢¼å•é¡Œã€‚

**åƒæ•¸**:
- `text` (str): è¦è¼¸å‡ºçš„æ–‡å­—

**ç¯„ä¾‹**:
```python
from src.utils.windows_encoding_utils import safe_print

safe_print("âœ… æ“ä½œæˆåŠŸ")  # Windows æœƒé¡¯ç¤º "[PASS] æ“ä½œæˆåŠŸ"
```

**å­—ç¬¦å°æ‡‰è¡¨**:
- `âœ…` â†’ `[PASS]`
- `âŒ` â†’ `[FAIL]`
- `âš ï¸` â†’ `[WARN]`
- `ğŸ‰` â†’ `[DONE]`
- `ğŸ”` â†’ `[SEARCH]`

##### `check_encoding_support()`

æª¢æŸ¥ç•¶å‰ç’°å¢ƒçš„ç·¨ç¢¼æ”¯æ´ã€‚

**è¿”å›å€¼**:
- `dict`: ç·¨ç¢¼æ”¯æ´è³‡è¨Š

---

## ğŸ”§ é…ç½® API

### å¸³è™Ÿé…ç½®æ ¼å¼

```json
{
  "accounts": [
    {
      "username": "å¸³è™Ÿåç¨±",
      "password": "å¯†ç¢¼",
      "enabled": true,
      "display_name": "é¡¯ç¤ºåç¨± (å¯é¸)"
    }
  ],
  "settings": {
    "headless": false,
    "download_base_dir": "./downloads",
    "timeout": 30,
    "retry_count": 3
  }
}
```

### ç’°å¢ƒé…ç½® (.env)

```bash
# Chrome åŸ·è¡Œæª”è·¯å¾‘
CHROME_BINARY_PATH="/path/to/chrome"

# æ—¥èªŒç´šåˆ¥
LOG_LEVEL="INFO"

# ä¸‹è¼‰è¶…æ™‚æ™‚é–“ (ç§’)
DOWNLOAD_TIMEOUT="60"
```

---

## ğŸ“Š å›å‘¼å’Œäº‹ä»¶ API

### äº‹ä»¶è™•ç†å™¨

å¯ä»¥è¨»å†Šäº‹ä»¶è™•ç†å™¨ä¾†ç›£è½çˆ¬èŸ²åŸ·è¡Œéç¨‹ï¼š

```python
class CustomEventHandler:
    def on_login_success(self, account, scraper):
        """ç™»å…¥æˆåŠŸæ™‚è§¸ç™¼"""
        print(f"âœ… {account['username']} ç™»å…¥æˆåŠŸ")

    def on_login_failed(self, account, error):
        """ç™»å…¥å¤±æ•—æ™‚è§¸ç™¼"""
        print(f"âŒ {account['username']} ç™»å…¥å¤±æ•—: {error}")

    def on_data_extracted(self, account, data):
        """è³‡æ–™æå–å®Œæˆæ™‚è§¸ç™¼"""
        print(f"ğŸ“Š {account['username']} æå– {len(data)} ç­†è³‡æ–™")

# ä½¿ç”¨äº‹ä»¶è™•ç†å™¨
handler = CustomEventHandler()
scraper = PaymentScraper()
scraper.add_event_handler(handler)
```

---

## ğŸ› ç•°å¸¸é¡åˆ¥ API

### è‡ªå®šç¾©ç•°å¸¸

```python
class ScraperError(Exception):
    """çˆ¬èŸ²åŸºç¤ç•°å¸¸"""
    pass

class LoginError(ScraperError):
    """ç™»å…¥ç›¸é—œç•°å¸¸"""
    pass

class CaptchaError(ScraperError):
    """é©—è­‰ç¢¼è™•ç†ç•°å¸¸"""
    pass

class DataExtractionError(ScraperError):
    """è³‡æ–™æå–ç•°å¸¸"""
    pass

class ConfigurationError(ScraperError):
    """é…ç½®éŒ¯èª¤ç•°å¸¸"""
    pass
```

### ç•°å¸¸è™•ç†ç¯„ä¾‹

```python
try:
    scraper = PaymentScraper()
    results = scraper.execute(account_info)
except LoginError as e:
    print(f"ç™»å…¥å¤±æ•—: {e}")
except CaptchaError as e:
    print(f"é©—è­‰ç¢¼è™•ç†å¤±æ•—: {e}")
except DataExtractionError as e:
    print(f"è³‡æ–™æå–å¤±æ•—: {e}")
except ScraperError as e:
    print(f"çˆ¬èŸ²éŒ¯èª¤: {e}")
```

---

## ğŸ”Œ æ“´å±• API

### å»ºç«‹è‡ªå®šç¾©çˆ¬èŸ²

```python
from src.core.base_scraper import BaseScraper

class CustomScraper(BaseScraper):
    """è‡ªå®šç¾©çˆ¬èŸ²ç¯„ä¾‹"""

    def get_query_params(self):
        """å¯¦ä½œæŸ¥è©¢åƒæ•¸"""
        return {
            'query_type': 'custom',
            'date_range': self.date_range
        }

    def process_results(self):
        """å¯¦ä½œçµæœè™•ç†"""
        # è‡ªå®šç¾©è™•ç†é‚è¼¯
        results = []
        # ... è™•ç†é‚è¼¯
        return results

    def setup_additional_options(self):
        """å¯é¸ï¼šé¡å¤–è¨­ç½®é‚è¼¯"""
        # è‡ªå®šç¾©è¨­ç½®
        pass

# ä½¿ç”¨è‡ªå®šç¾©çˆ¬èŸ²
scraper = CustomScraper()
manager = MultiAccountManager(CustomScraper)
```

### è‡ªå®šç¾©ç€è¦½å™¨å·¥å» 

```python
class CustomWebDriverFactory:
    """è‡ªå®šç¾©ç€è¦½å™¨å·¥å» """

    @staticmethod
    def create_firefox_driver(config):
        """å»ºç«‹ Firefox WebDriver"""
        from selenium import webdriver
        from selenium.webdriver.firefox.options import Options

        options = Options()
        if config.get('headless'):
            options.add_argument('--headless')

        return webdriver.Firefox(options=options)

# åœ¨ BaseScraper ä¸­ä½¿ç”¨
class FirefoxScraper(BaseScraper):
    def setup_browser(self):
        factory = CustomWebDriverFactory()
        self.driver = factory.create_firefox_driver(self.config)
```

---

## ğŸ“ˆ ç›£æ§å’Œæ—¥èªŒ API

### æ—¥èªŒé…ç½®

```python
import logging

# è¨­å®šæ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/scraper.log'),
        logging.StreamHandler()
    ]
)

# åœ¨çˆ¬èŸ²ä¸­ä½¿ç”¨
class PaymentScraper(BaseScraper):
    def __init__(self):
        super().__init__()
        self.logger = logging.getLogger(self.__class__.__name__)
```

### æ•ˆèƒ½ç›£æ§

```python
import time
from functools import wraps

def monitor_performance(func):
    """æ•ˆèƒ½ç›£æ§è£é£¾å™¨"""
    @wraps(func)
    def wrapper(*args, **kwargs):
        start_time = time.time()
        try:
            result = func(*args, **kwargs)
            duration = time.time() - start_time
            print(f"âœ… {func.__name__} åŸ·è¡Œå®Œæˆï¼Œè€—æ™‚ {duration:.2f} ç§’")
            return result
        except Exception as e:
            duration = time.time() - start_time
            print(f"âŒ {func.__name__} åŸ·è¡Œå¤±æ•—ï¼Œè€—æ™‚ {duration:.2f} ç§’: {e}")
            raise
    return wrapper

# ä½¿ç”¨ç›£æ§è£é£¾å™¨
class MonitoredScraper(BaseScraper):
    @monitor_performance
    def login(self, username, password):
        return super().login(username, password)

    @monitor_performance
    def process_results(self):
        return super().process_results()
```

---

## ğŸ”„ ç‰ˆæœ¬ç›¸å®¹æ€§

### API ç‰ˆæœ¬

- **ç•¶å‰ç‰ˆæœ¬**: 2.0.0
- **æœ€å°æ”¯æ´ Python**: 3.8
- **æ¨è–¦ Python**: 3.11+

### å‘å‰ç›¸å®¹æ€§

```python
# æª¢æŸ¥ API ç‰ˆæœ¬
from src import __version__

if __version__ >= '2.0.0':
    # ä½¿ç”¨æ–° API
    scraper = PaymentScraper(config={'timeout': 30})
else:
    # ä½¿ç”¨èˆŠ API
    scraper = PaymentScraper()
    scraper.timeout = 30
```

### æ£„ç”¨è­¦å‘Š

```python
import warnings

def deprecated_method():
    """å·²æ£„ç”¨çš„æ–¹æ³•"""
    warnings.warn(
        "æ­¤æ–¹æ³•å°‡åœ¨ v3.0 ä¸­ç§»é™¤ï¼Œè«‹ä½¿ç”¨ new_method() æ›¿ä»£",
        DeprecationWarning,
        stacklevel=2
    )
```

é€™ä»½ API æ–‡æª”æä¾›äº† SeleniumPelican çš„å®Œæ•´ç¨‹å¼ä»‹é¢åƒè€ƒï¼Œå¹«åŠ©é–‹ç™¼è€…æœ‰æ•ˆåˆ©ç”¨å’Œæ“´å±•å°ˆæ¡ˆåŠŸèƒ½ã€‚
